# train.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, SubsetRandomSampler
from torchvision.transforms import transforms
from sklearn.model_selection import KFold
from tqdm import tqdm
import logging
from dataloaders import get_dataloaders  # 确保这个模块正确实现了数据加载
from vgg_attention_model import VGGAttentionModel  # 确保包含了SelfAttention的VGG模型
from vit_model import ViTFeatureExtractor  # 确保包含了适用于您任务的ViT模型实现
from fusion import BilinearAttentionPooling  # 确保这个模块实现了您想要的特征融合方法


def save_model(model, filename):
    torch.save(model.state_dict(), filename)
    
# MLP分类器定义
class MLPClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.2):
        super(MLPClassifier, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout_rate)  # 加入Dropout层
        self.fc2 = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)  # 应用Dropout
        x = self.fc2(x)
        return x

# 设置日志记录
logging.basicConfig(filename='training2.log', level=logging.INFO, format='%(asctime)s - %(message)s')

# 设定基本参数
num_epochs = 5
batch_size = 32
learning_rate_vgg = 2e-6
learning_rate_vit = 2e-6
num_splits = 5
patience = 3

output_dim = 512  # 根据您的任务调整
hidden_dim = 1024  # MLP隐藏层维度
num_classes = 9  # 根据您的任务调整类别数
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# 数据加载   注意这里用你的文件的绝对路径     你的绝对路径/train   你的绝对路径/train_asm
dataloaders = get_dataloaders('/home/a19220413/jupyterlab/malware_classfication/train_png', '/home/a19220413/jupyterlab/malware_classfication/clj/train_asm', 'trainLabels_new.csv', batch_size, transform=transform, shuffle=True)

# 模型定义
vgg_attention_model = VGGAttentionModel(pretrained=True).to(device)
vit_model = ViTFeatureExtractor().to(device)

feature1_dim = 200704 # VGG特征维度
feature2_dim = 1000   # ViT特征维度
hidden_dim = 1024     # 隐藏层维度
ban_fusion = BilinearAttentionPooling(feature1_dim, feature2_dim, hidden_dim).to(device)

# MLP分类器定义时使用正确的输入维度
mlp_classifier = MLPClassifier(input_dim=1024, hidden_dim=hidden_dim, num_classes=num_classes).to(device)


# 损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer_vgg = optim.Adam(vgg_attention_model.parameters(), lr=learning_rate_vgg)
optimizer_vit = optim.Adam(vit_model.parameters(), lr=learning_rate_vit)
optimizer_fusion = optim.Adam(ban_fusion.parameters(), lr=max(learning_rate_vgg, learning_rate_vit))
optimizer_mlp = optim.Adam(mlp_classifier.parameters(), lr=1e-5)

# 多GPU支持
if torch.cuda.device_count() > 1:
    print(f"Let's use {torch.cuda.device_count()} GPUs!")
    vgg_attention_model = nn.DataParallel(vgg_attention_model)
    vit_model = nn.DataParallel(vit_model)
    ban_fusion = nn.DataParallel(ban_fusion)
    mlp_classifier = nn.DataParallel(mlp_classifier)

# K折交叉验证
# K折交叉验证
kf = KFold(n_splits=num_splits, shuffle=True)
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 保留原有的导入和模型定义

# 在训练和验证循环中添加性能评估
for fold, (train_idx, val_idx) in enumerate(kf.split(dataloaders.dataset)):
    print(f'Fold {fold+1}/{num_splits}')
    train_sampler = SubsetRandomSampler(train_idx)
    val_sampler = SubsetRandomSampler(val_idx)
    train_loader = DataLoader(dataloaders.dataset, batch_size=batch_size, sampler=train_sampler)
    val_loader = DataLoader(dataloaders.dataset, batch_size=batch_size, sampler=val_sampler)

    for epoch in range(num_epochs):
        # 训练阶段
        vgg_attention_model.train()
        vit_model.train()
        ban_fusion.train()
        mlp_classifier.train()
        train_loss = 0.0
        train_predictions = []
        train_labels = []

        for data in tqdm(train_loader, desc=f"Training (Epoch {epoch+1}/{num_epochs})"):
            mal_imgs, _, labels = data
            labels = labels.to(device)
            mal_imgs = mal_imgs.to(device)

            # 训练过程中的特征提取和融合
            # 假设简单地将所有ViT特征平均化
            features_vit_list = []
            for i in range(mal_imgs.size(1)):
                img = mal_imgs[:, i, :, :, :]
                feature_vit = vit_model(img)
                features_vit_list.append(feature_vit)
            features_vit = torch.mean(torch.stack(features_vit_list), dim=0)
            
            # 使用VGG模型提取特征
            features_vgg = vgg_attention_model(mal_imgs)
            
            # 融合VGG和ViT特征
            fused_features = ban_fusion(features_vgg, features_vit)

            # 使用MLP分类器进行分类
            predictions = mlp_classifier(fused_features)

            # 计算损失并执行反向传播和优化
            loss = criterion(predictions, labels)
            optimizer_vgg.zero_grad()
            optimizer_vit.zero_grad()
            optimizer_fusion.zero_grad()
            optimizer_mlp.zero_grad()
            loss.backward()
            optimizer_vgg.step()
            optimizer_vit.step()
            optimizer_fusion.step()
            optimizer_mlp.step()

            train_loss += loss.item()

            # 收集预测和标签用于训练指标计算
            _, predicted = torch.max(predictions.data, 1)
            train_predictions.extend(predicted.cpu().numpy())
            train_labels.extend(labels.cpu().numpy())

        # 计算训练指标
        train_accuracy = accuracy_score(train_labels, train_predictions)
        train_precision = precision_score(train_labels, train_predictions, average='macro', zero_division=0)
        train_recall = recall_score(train_labels, train_predictions, average='macro', zero_division=0)
        train_f1 = f1_score(train_labels, train_predictions, average='macro', zero_division=0)

        print(f"Train Loss: {train_loss / len(train_loader)}")
        print(f"Train Accuracy: {train_accuracy}, Precision: {train_precision}, Recall: {train_recall}, F1 Score: {train_f1}")
        logging.info(f"Fold {fold+1}/{num_splits}, Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss / len(train_loader)}, Accuracy: {train_accuracy}, Precision: {train_precision}, Recall: {train_recall}, F1 Score: {train_f1}")
#         save_model(vgg_attention_model, f'model/vgg_attention_model_epoch_{epoch+1}.pth')
#         save_model(vit_model, f'model/vit_model_epoch_{epoch+1}.pth')
#         save_model(ban_fusion, f'model/ban_fusion_epoch_{epoch+1}.pth')
#         save_model(mlp_classifier, f'model/mlp_classifier_epoch_{epoch+1}.pth')


        
 # 在每个训练epoch之后添加验证阶段
        vgg_attention_model.eval()
        vit_model.eval()
        ban_fusion.eval()
        mlp_classifier.eval()

        val_loss = 0.0
        val_predictions = []
        val_labels = []

        with torch.no_grad():  # 确保在评估模式下不计算梯度
            for data in tqdm(val_loader, desc=f"Validating (Epoch {epoch+1}/{num_epochs}, Fold {fold+1})"):
                mal_imgs, _, labels = data
                labels = labels.to(device)
                mal_imgs = mal_imgs.to(device)

                # 验证过程中的特征提取和融合与训练相同
                features_vit_list = []
                for i in range(mal_imgs.size(1)):
                    img = mal_imgs[:, i, :, :, :]
                    feature_vit = vit_model(img)
                    features_vit_list.append(feature_vit)
                features_vit = torch.mean(torch.stack(features_vit_list), dim=0)
                
                features_vgg = vgg_attention_model(mal_imgs)
                fused_features = ban_fusion(features_vgg, features_vit)
                
                # 使用MLP分类器进行分类
                predictions = mlp_classifier(fused_features)

                # 计算损失
                loss = criterion(predictions, labels)
                val_loss += loss.item()

                # 收集预测和标签用于性能评估
                _, predicted = torch.max(predictions.data, 1)
                val_predictions.extend(predicted.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())

        # 计算验证集上的性能指标
        val_accuracy = accuracy_score(val_labels, val_predictions)
        val_precision = precision_score(val_labels, val_predictions, average='macro', zero_division=0)
        val_recall = recall_score(val_labels, val_predictions, average='macro', zero_division=0)
        val_f1 = f1_score(val_labels, val_predictions, average='macro', zero_division=0)

        print(f"Validation Loss: {val_loss / len(val_loader)}")
        print(f"Validation Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {val_f1}")
        logging.info(f"Fold {fold+1}/{num_splits}, Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss / len(val_loader)}, Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {val_f1}")


# 在所有fold的训练结束后保存模型
save_model(vgg_attention_model, './model/vgg_attention_model_final.pth')
save_model(vit_model, './model/vit_model_final.pth')
save_model(ban_fusion, './model/ban_fusion_final.pth')
save_model(mlp_classifier, './model/mlp_classifier_final.pth')
