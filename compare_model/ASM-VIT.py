# import torch
# import torch.nn as nn
# import torch.optim as optim
# # from torchvision.models import vit_l_32


# from torchvision import transforms
# from torch.utils.data import Dataset, DataLoader
# import pandas as pd
# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# from tqdm import tqdm
# from PIL import Image
# import os
# import torch
# from torchvision.models import vit_h_14, ViT_H_14_Weights

# # 定义数据集类
# class CustomDataset(Dataset):
#     def __init__(self, folder_path, label_file, transform=None):
#         self.folder_path = folder_path
#         self.label_file = label_file
#         self.transform = transform
#         self.labels = pd.read_csv(label_file)

#     def __len__(self):
#         return len(self.labels)

#     def __getitem__(self, idx):
#         img_name = os.path.join(self.folder_path, str(self.labels.iloc[idx, 0]) + '.png')
#         image = Image.open(img_name).convert('RGB')
#         label = int(self.labels.iloc[idx, 1]-1)

#         if self.transform:
#             image = self.transform(image)

#         return image, label


# # 加载数据
# train_folder = 'train_asm'
# test_folder = 'test_asm'
# train_label_file = 'trainLabels_new.csv'
# test_label_file = 'testLabels_new.csv'

# # 图像预处理
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
# ])

# train_dataset = CustomDataset(train_folder, train_label_file, transform=transform)
# test_dataset = CustomDataset(test_folder, test_label_file, transform=transform)

# # 数据加载器
# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# # 定义ViT模型
# model_vit = vit_h_14(pretrained=True)
# input_dim = 1000
# print(model_vit.heads.head.out_features)

# # 提取特征的MLP
# class MLP(nn.Module):
#     def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.2):
#         super(MLP, self).__init__()
#         self.fc1 = nn.Linear(input_dim, hidden_dim) 
#         self.relu = nn.ReLU()
#         self.dropout = nn.Dropout(dropout_rate)  # 加入Dropout层
#         self.fc2 = nn.Linear(hidden_dim, num_classes)

#     def forward(self, x):
#         x = self.fc1(x)
#         x = self.relu(x)
#         x = self.dropout(x)  # 应用Dropout
#         x = self.fc2(x)
#         return x

# # 定义模型
# # 定义模型
#   # ViT输出的特征维度
# hidden_dim = 900
# output_dim = 9  # 类别数
# mlp_model = MLP(input_dim, hidden_dim, output_dim)

# # 使用torch.nn.DataParallel自动进行多GPU训练
# if torch.cuda.device_count() > 1:
#     print(f"Let's use {torch.cuda.device_count()} GPUs!")
#     mlp_model = nn.DataParallel(mlp_model)

# # 损失函数和优化器
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(mlp_model.parameters(), lr=0.00025)

# # 将模型移到默认的设备上
# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# model_vit.to(device)
# mlp_model.to(device)


# # 训练
# num_epochs = 30

# for epoch in range(num_epochs):
#     mlp_model.train()
#     running_loss = 0.0
#     for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):
#         images, labels = images.to(device), labels.to(device)

#         with torch.set_grad_enabled(True):
#             features = model_vit(images)
#             outputs = mlp_model(features)
#             loss = criterion(outputs, labels)

#             optimizer.zero_grad()
#             loss.backward()
#             optimizer.step()

#             running_loss += loss.item() * images.size(0)

#     epoch_loss = running_loss / len(train_dataset)
#     print(f'Training Loss: {epoch_loss:.4f}')

#     # 在每个epoch结束后评估模型
#     mlp_model.eval()
#     all_predictions = []
#     all_labels = []

#     with torch.no_grad():
#         for images, labels in tqdm(test_loader, desc='Testing', unit='batch'):
#             images, labels = images.to(device), labels.to(device)

#             features = model_vit(images)
#             outputs = mlp_model(features)
#             _, predicted = torch.max(outputs, 1)

#             all_predictions.extend(predicted.cpu().numpy())
#             all_labels.extend(labels.cpu().numpy())

#     accuracy = accuracy_score(all_labels, all_predictions)
#     precision = precision_score(all_labels, all_predictions, average='macro')
#     recall = recall_score(all_labels, all_predictions, average='macro')
#     f1 = f1_score(all_labels, all_predictions, average='macro')

#     print(f'Epoch {epoch+1} Evaluation:')
#     print(f'Accuracy: {accuracy:.4f}')
#     print(f'Precision: {precision:.4f}')
#     print(f'Recall: {recall:.4f}')
#     print(f'F1 Score: {f1:.4f}')

# # import torch
# # from torchvision.models import vit_l_32

# # # 加载预训练的模型
# # model = vit_l_32(pretrained=True)

# # # 打印模型结构
# # print(model)

# # # 假设我们想要获取模型最后一层的输出特征维度
# # # 这通常是分类器前的最后一个线性层的输出特征数量
# # # 对于Vision Transformer，这通常是隐藏层的大小
# # output_features = model.heads.head.in_features
# # print(f"Output feature dimension: {output_features}")
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.models import vit_h_14, ViT_H_14_Weights
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from PIL import Image
from tqdm import tqdm

class CustomDataset(Dataset):
    def __init__(self, folder_path, label_file, transform=None):
        self.folder_path = folder_path
        self.label_file = label_file
        self.transform = transform
        self.labels = pd.read_csv(label_file)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        img_name = os.path.join(self.folder_path, str(self.labels.iloc[idx, 0]) + '.png')
        image = Image.open(img_name).convert('RGB')
        label = int(self.labels.iloc[idx, 1]-1)

        if self.transform:
            image = self.transform(image)

        return image, label

train_folder = 'train_asm'
test_folder = 'test_asm'
train_label_file = 'trainLabels_new.csv'
test_label_file = 'testLabels_new.csv'

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_dataset = CustomDataset(train_folder, train_label_file, transform=transform)
test_dataset = CustomDataset(test_folder, test_label_file, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# 使用ViT预训练模型
model_vit = vit_h_14(weights=ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1)

# 使用虚拟输入获取特征层输出维度
dummy_input = torch.randn(1, 3, 224, 224)  # 假设输入大小为 3x224x224
features = model_vit(dummy_input)
input_dim = features.shape[1]  # 获取特征维度

class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.2):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout_rate)
        self.fc2 = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x

hidden_dim = 900
num_classes = 9
mlp_model = MLP(input_dim, hidden_dim, num_classes)

if torch.cuda.device_count() > 1:
    print(f"Let's use {torch.cuda.device_count()} GPUs!")
    mlp_model = nn.DataParallel(mlp_model)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(mlp_model.parameters(), lr=0.00025)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_vit.to(device)
mlp_model.to(device)

num_epochs = 30
for epoch in range(num_epochs):
    mlp_model.train()
    running_loss = 0.0
    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        features = model_vit(images)
        outputs = mlp_model(features)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

    epoch_loss = running_loss / len(train_dataset)
    print(f'Training Loss: {epoch_loss:.4f}')

    mlp_model.eval()
    all_predictions = []
    all_labels = []
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc='Testing', unit='batch'):
            images, labels = images.to(device), labels.to(device)
            features = model_vit(images)
            outputs = mlp_model(features)
            _, predicted = torch.max(outputs, 1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_predictions)
    precision = precision_score(all_labels, all_predictions, average='macro')
    recall = recall_score(all_labels, all_predictions, average='macro')
    f1 = f1_score(all_labels, all_predictions, average='macro')

    print(f'Epoch {epoch+1} Evaluation:')
    print(f'Accuracy: {accuracy:.4f}')
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1 Score: {f1:.4f}')
